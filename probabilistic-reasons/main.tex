\documentclass[11pt, letterpaper]{article}

%% Packages & Macros
\usepackage[
letterpaper,
top=1.2in,
bottom=1.2in,
left=1in,
right=1in]{geometry}

\usepackage[dvipsnames]{xcolor}

\usepackage{amsthm, amsmath, amssymb}
\usepackage{mathtools}
\usepackage{tikz}
\usepackage{todonotes}
\usepackage{pgfplots}
\pgfplotsset{compat=1.18}

\usepackage{lipsum}
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography  
\usepackage{tabularx}
\usepackage[T1]{fontenc}
\usepackage[full]{textcomp}
\usepackage[american]{babel}
% \usepackage{stmaryrd}

\usepackage{paralist}
\usepackage{turnstile}
\usepackage{mdframed}
\usepackage{tikz}
\usepackage{caption}


\usepackage{mathpazo}
%\usepackage{euler}
%\usepackage{libertine} % T1, lining figures in math, osf in text
\usepackage{textcomp} % required for special glyphs
\usepackage[varg,bigdelims]{newpxmath}


\usepackage[colorlinks=true,
linkcolor=purple,
urlcolor=blue,
citecolor=purple,
linktocpage=true]{hyperref} 

\usepackage[capitalise,nameinlink]{cleveref}
\crefname{lemma}{Lemma}{Lemmas}
\crefname{fact}{Fact}{Facts}


\usepackage{libertine}
\usepackage[linesnumbered, ruled, vlined]{algorithm2e}

\newtheorem{fact}{Fact}
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem{definition}{Definition}
\newtheorem{proposition}{Proposition}
\newtheorem{example}{Example}

\newcommand{\M}{\mathcal{M}}
\newcommand{\Lin}{\mathcal{L}}
\newcommand{\B}{\{0, 1\}}

\input{math_commands.tex}
% \newcommand{\vx}{\vec{x}}
% \newcommand{\vy}{\vec{y}}
% \newcommand{\vz}{\vec{z}}

\newcommand{\sharpK}{\textsc{\#Knapsack}}
\newcommand{\Knapsack}{\textsc{Knapsack}}

\newcommand{\D}{\mathbf{D}}

% \newcommand{\E}{\mathbb{E}}

\newcommand{\ptime}{\mathrm{P}}

\DeclareMathOperator{\comp}{Comp}

\newcommand{\csproblem}[3]{
    \begin{center}
    \fbox{\begin{tabular}{lp{8cm}}
    {\small PROBLEM:} : & #1 \\
    {\small INPUT} : & #2 %of dimension $d$, 
    %\\ & $x \in \{0,1\}^d$ an instance, and $0 \leq \delta \leq 1$
    \\ 
    {\small OUTPUT} : & #3\\
    \end{tabular}}
    \end{center}
    }

\usepackage{bm}
\linespread{1.05}
\usepackage{microtype}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% FORMATTING
\allowdisplaybreaks
\newcommand{\FormatAuthor}[3]{
\begin{tabular}{c}
#1 \\ {\small\texttt{#2}} \\ {\small #3}
\end{tabular}
}
\newcommand{\doclearpage}{%
\iffull
\clearpage
\else
\fi
}
\newcommand{\defemph}[1]{\textbf{\emph{#1}}}
\newcommand{\keywords}[1]{\bigskip\par\noindent{\footnotesize\textbf{Keywords\/}: #1}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%% End Packages & Macros

\title{Probabilistic Explanations for Linear Models}
\author{
    \begin{tabular}[h!]{ccc}
        \FormatAuthor{Marcelo Arenas}{\url{marenas@ing.puc.cl}}{PUC Chile}
        \FormatAuthor{Kuldeep S. Meel}{\url{meel@cs.toronto.edu}}{University of Toronto}
        \FormatAuthor{Bernardo Subercaseaux}{\url{bersub@cmu.edu}}{Carnegie Mellon University}
  \end{tabular}
}

\begin{document}
\maketitle

\begin{abstract}
We study the problem of computing \emph{probabilistic minimum sufficient reasons} for linear models, providing approximation algorithms with different guarantees on the explanation size as well as on the explanation probability.  As opposed to previous work, which only considered i.i.d. settings, we consider the more general case of product distributions. 
\end{abstract}


\section{Introduction}

Explaining the decisions of Machine Learning classifiers is a fundamental problem in XAI (Explainable AI), and doing so with formal mathematical guarantees on the quality, size, and semantics of the explanations is in turn the core of \emph{Formal XAI}~\cite{formal-xai}. 
Within formal XAI, one of the most studied kinds of explanations is that of \emph{sufficient reasons}~\cite{Darwiche_Hirth_2020}, which aim to explain a decision $\M(\vx) = 1$ by presenting a subset $S$ of the features of the input $\vx$ that implies $\M(\vz) = 1$  for any $\vz$ that agrees with $\vx$ on $S$. 
In the language of theoretical computer science, these correspond to \emph{certificates} for $\M(\vx)$.

\begin{example}
Consider a binary classifier~$\M$ defined as 
	\[
	\M(\vx) = \left(x_1 \lor \overline{x_3}\right) \land   \left(x_2 \lor \overline{x_1}\right) \land \left(x_4 \lor x_3\right),
	\]
	and the input instance $\vx = \left( 1, \,  1, \, 0, \, 1 \right)$. We can say that $\M(\vx)$ ``because'' $x_1 = 1, x_2 = 1$, and $x_4 = 1$, as they are sufficient to determine the value of $\M(\vx)$ regardless of $x_3$.
	\label{ex:sufficient-reason}
\end{example}

Let us start formalizing the framework for our work.  First, we consider binary boolean models $\M\colon \{0, 1\}^d \to \{0, 1\}$. Despite our domain being binary, we will need a third value, $\bot$, to denote \emph{``unknown''} values.  For example, we may represent a person who \emph{does} have a car, \emph{does not} have a house, and for whom we do not know if they have a pet or not, as $\left(1, \, 0, \, \bot\right)$. 
We say elements of $\{0, 1, \bot\}^d$ are \emph{partial instances}, while elements of $\{0, 1\}^d$ are simply \emph{instances}. To illustrate, in~\Cref{ex:sufficient-reason} we used the partial instance $\vy = \left(1, \, 1, \, \bot, \, 1 \right)$ to explain $\M(\vx) = 1$.
We use the notation $\vy \subseteq \vx$ to denote that the (partial) instance $\vx$ \emph{``fills in''} values of the partial instance $\vy$; more formally, we use $\vy \subseteq \vx$ to mean that $y_i = \bot \lor y_i = x_i$ for every $i \in [d]$. Finally, for any partial instance $\vy$ we denote by $\comp(\vy)$ the set of instances $\vx$ such that $\vy \subseteq \vx$, thinking of $\comp(\vy)$ as the set of \emph{completions} of $\vy$. One can define sufficient reasons as follows with this notation.

\begin{definition}[Sufficient Reason~\cite{Darwiche_Hirth_2020}]
	We say $\vy$ is a \emph{sufficient reason} for $\vx$ if for any completion $\vz \in \comp(\vy)$ it holds that $\M(\vx) = \M(\vz)$.
	\label{def:sufficient-reason}
\end{definition}
A crucial factor for the helpfulness of sufficient reasons as explanations is their size; even though $\vx$ is always a sufficient reason for its own classification, we long for explanations that are much smaller than $\vx$ itself. Miller, for instance, goes on to say that explanations consisting of more than $9$ features are probably too large for human stakeholders~\cite{millerMagicalNumberSeven1956}. In general, previous research suggests that explanations ought to be small~\cite{Narayanan_Chen_He_Kim_Gershman_Doshi-Velez_2018, Lage_Chen_He_Narayanan_Kim_Gershman_Doshi-Velez_2019}.
There are several ways of formalizing the succinctness we desire for sufficient reasons:

\begin{itemize}
    \item \textbf{(Minimum Size)} For a sufficient reason $\vy$, we define its \emph{explanation size} $|\vy|_e$ as the number of defined features in $\vy$, or equivalently, $|\vy|_e := d - |\vy|_\bot$, where $|\vy|_\bot$ is the number of features of $\vy$ taking $\bot$. See e.g.,~\cite{NEURIPS2020_b1adda14}.
    \item \textbf{(Minimality)} We say a sufficient reason $\vy$ for a pair $(\M, \vx)$ is \emph{minimal} if there is no other sufficient reason $\vy'$ for $(\M, \vx)$ such that $\vy' \subsetneq \vy$. In fact, the original definition of sufficient reasons of~\cite{Darwiche_Hirth_2020} includes minimality as a requirement, and so is the case under the \emph{``abductive explanation''} naming~\cite{Ignatiev_Narodytska_Asher_Marques-Silva_2021}.
    \item \textbf{(Compared to the average explanation)} The work of~\cite{blanc2021provably} computes explanations that are small relative to the \emph{``certificate complexity''} of the classifier $\M$, meaning the average size of the minimum sufficient reason where the average is taken over all possible instances $\vx$.
\end{itemize}

Nevertheless, there is a path toward even smaller explanations: \emph{probabilistic} sufficient reasons~\cite{Waldchen_MacDonald_Hauch_Kutyniok_2021, Izza_Huang_Ignatiev_Narodytska_Cooper_Marques-Silva_2023}. 
As will be shown in Example 2., and is noted as a remark by~\cite{blanc2021provably}, these can be arbitrarily smaller than minimum size sufficient reasons.

\input{prob-sufficient-reasons.tex}

\input{computational-problems.tex}

\input{locally-minimal.tex}

\bibliography{references}
\bibliographystyle{alpha}
\end{document}
