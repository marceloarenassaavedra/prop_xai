\documentclass[11pt, letterpaper]{article}

%% Packages & Macros
\usepackage[
letterpaper,
top=1.2in,
bottom=1.2in,
left=1in,
right=1in]{geometry}

\usepackage[dvipsnames]{xcolor}

\usepackage{amsthm, amsmath, amssymb}
\usepackage{mathtools}
\usepackage{tikz}
\usepackage{todonotes}
\usepackage{pgfplots}
\pgfplotsset{compat=1.18}

\usepackage{lipsum}
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography  
\usepackage{tabularx}
\usepackage[T1]{fontenc}
\usepackage[full]{textcomp}
\usepackage[american]{babel}
\usepackage{booktabs}

% \usepackage{stmaryrd}

\usepackage{paralist}
\usepackage{turnstile}
\usepackage{mdframed}
\usepackage{tikz}
\usepackage{caption}


\usepackage{mathpazo}
%\usepackage{euler}
%\usepackage{libertine} % T1, lining figures in math, osf in text
\usepackage{textcomp} % required for special glyphs
\usepackage[varg,bigdelims]{newpxmath}


\usepackage[colorlinks=true,
linkcolor=purple,
urlcolor=blue,
citecolor=purple,
linktocpage=true]{hyperref} 

\usepackage[capitalise,nameinlink]{cleveref}
\crefname{lemma}{Lemma}{Lemmas}
\crefname{fact}{Fact}{Facts}




\newtheorem{fact}{Fact}
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem{definition}{Definition}
\newtheorem{proposition}{Proposition}
\newtheorem{example}{Example}
\newtheorem{open}{Open Problem}

\newcommand{\M}{\mathcal{M}}
\newcommand{\U}{\mathbf{U}}
\newcommand{\D}{\mathbf{D}}
\newcommand{\Lin}{\mathcal{L}}
\newcommand{\ptime}{\mathrm{P}}
\newcommand{\np}{\mathrm{NP}}
\newcommand{\fptime}{\mathrm{FP}}
\newcommand{\shp}{\mathrm{\#P}}
\newcommand{\Knapsack}{\textsc{Knapsack}}
\newcommand{\opt}{\operatorname{\textsc{Min}}}


\DeclareMathOperator{\comp}{Comp}


\usepackage{libertine}
% \usepackage[linesnumbered, ruled, vlined]{algorithm2e}

\usepackage{algorithm}
\usepackage{algorithmic}

\usepackage{natbib}



\input{math_commands.tex}
% \newcommand{\vx}{\vec{x}}
% \newcommand{\vy}{\vec{y}}
% \newcommand{\vz}{\vec{z}}




% \newcommand{\E}{\mathbb{E}}

\newcommand{\csproblem}[3]{
    \begin{center}
    \fbox{\begin{tabular}{lp{8cm}}
    {\small PROBLEM:} : & #1 \\
    {\small INPUT} : & #2 %of dimension $d$, 
    %\\ & $x \in \{0,1\}^d$ an instance, and $0 \leq \delta \leq 1$
    \\ 
    {\small OUTPUT} : & #3\\
    \end{tabular}}
    \end{center}
    }

\usepackage{bm}
\linespread{1.05}
\usepackage{microtype}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% FORMATTING
\allowdisplaybreaks
\newcommand{\FormatAuthor}[3]{
\begin{tabular}{c}
#1 \\ {\small\texttt{#2}} \\ {\small #3}
\end{tabular}
}
\newcommand{\doclearpage}{%
\iffull
\clearpage
\else
\fi
}
\newcommand{\defemph}[1]{\textbf{\emph{#1}}}
\newcommand{\keywords}[1]{\bigskip\par\noindent{\footnotesize\textbf{Keywords\/}: #1}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%% End Packages & Macros

\title{Probabilistic Explanations for Linear Models}
\author{
    \begin{tabular}[h!]{ccc}
        \FormatAuthor{Marcelo Arenas}{\url{marenas@ing.puc.cl}}{PUC Chile}
        \FormatAuthor{Kuldeep S. Meel}{\url{meel@cs.toronto.edu}}{University of Toronto}
        \FormatAuthor{Bernardo Subercaseaux}{\url{bersub@cmu.edu}}{Carnegie Mellon University}
  \end{tabular}
}

\begin{document}
\maketitle

\begin{abstract}
    Formal XAI is an emerging field that focuses on providing explanations
    with mathematical guarantees for the decisions made by machine
    learning models. Recent work in this area has centered on the
    computation of ``sufficient reasons''. Given a model $\M$
    and an input instance $\vx$, a sufficient reason for the decision $\M(\vx)$ is a
    subset $S$ of the features of $\vx$ such that for any instance $\vz$
    that has the same values as $\vx$ for every feature in $S$, it holds that $\M(\vx) = \M(\vz)$. Intuitively, this means
    that the features in $S$ are sufficient to fully justify the
    classification of $\vx$ by $\M$.
    For sufficient reasons to be useful in practice, they should be as
    small as possible, and a natural way to reduce the size of sufficient
    reasons is to consider a
    probabilistic relaxation; the probability of $\M(\vx) = \M(\vz)$ must
    be at least some value $\delta \in (0,1]$, where $\vz$ is a random
      instance compatible with $\vx$.  Computing small $\delta$-sufficient reasons ($\delta$-SRs) is known to be a theoretically hard problem; even over decision trees — traditionally deemed simple and interpretable models — strong inapproximability results make the efficient computation of small $\delta$-SRs unlikely.
     We propose the notion of $(\delta, \epsilon)$-SR, a simple relaxation of $\delta$-SRs, and show that while this relaxation is hard to compute over decision trees (as a simple consequence of the previous inapproximability results), it can be computed efficiently over linear models. 
\end{abstract}

\section{Introduction}
\label{sec-into}
\input{sections/intro}

\section{Probabilistic Sufficient Reasons}
\label{sec-prop-SR}
\input{sections/prob-sufficient-reasons}

%\section{Computational Problem}
\section{Approximating \texorpdfstring{$\delta$}{delta}-Sufficient Reasons}
\label{sec-comp-problem}
\input{sections/new-computational-problems}

\section{Locally Minimal Probabilistic Explanations}
\label{sec-loc-min}
\input{sections/locally-minimal}

\section{Conclusions and Future Work}
\label{sec-conclusions}
\input{sections/conclusions}

\bibliographystyle{apalike}
\bibliography{references}


\newpage
\onecolumn
\appendix
\section*{Appendix}
\input{sections/appendix}


\end{document}
