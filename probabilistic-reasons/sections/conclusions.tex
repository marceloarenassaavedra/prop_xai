We have proved a positive result for the case of linear models, showing that a $(\delta, \varepsilon)$-min-SRs can be computed efficiently, and also a more abstract reason suggesting that linear models might be easier to explain than, e.g., decision trees. However,  a variety of natural questions and directions of research remain open. 
First, in practical terms, even though the runtime of~\Cref{prop:smoothed-explanation} is polynomial and only has a quasi-linear dependency on $d$, our future work includes lowering the dependency in $1/\varepsilon$ and $1/\gamma$; on a dataset with $d = 500$, setting $\varepsilon = 0.1$ and $\gamma = 0.01$ is already computationally expensive. 
We acknowledge, in terms of practical implementations, the work of~\citet{Louenas,izza2024locallyminimalprobabilisticexplanations} that allows for computing small probabilistic explanations over decision trees significantly faster than the exact SAT approach of~\citet{NEURIPS2022_b8963f6a}.
Similarly,~\citet{izzaComputingProbabilisticAbductive2023} showed solid practical results with different kinds of classifiers, including linear models (i.e., Naive Bayes). Despite our results having better theoretical guarantees over linear models, a natural direction of future work is to improve the practical efficiency of our algorithm for high-dimensional models.

Second, our theoretical result has some natural directions for generalization. We considered only binary features, whereas in order to offer a practically useful tool to the community, we will need to understand how to compute (approximate) probabilistic explanations for mixtures real-valued features and categorical features, for example under the ``extended linear classifier'' definition of~\citet{DBLP:conf/nips/0001GCIN20}.  Another fascinating theoretical question is handling the generalization of our setting to that of product distributions (i.e., feature $i$ takes value $1$ with probability $p_i$ and $0$ otherwise) can also be solved efficiently. A straightforward extension of our techniques does not seem to work on such a generalized setting, since the \emph{feature selection} argument of~\Cref{subsec:feature_selection} no longer holds. Therefore, we believe that new techniques will be needed.  
 
Third, it would be interesting to allow for a more declarative way of specifying the probabilistic guarantees or constraints on the explanations. While a recent line of research has studied the design of languages for defining explainability queries with a uniform algorithmic treatment~\citep{arenasFoundationsSymbolicLanguages2021,bps2020,KR2024-6}, we are not aware of any work on that line that allows for probabilistic terms.
% In terms of the theory, we sorely lack results on the (in)approximability of the size of minimum $\delta$-SRs without relaxing the value of $\delta$. We have shown nonetheless, in~\Cref{prop:delta-sr-size}, that we cannot simply obtain a smallest $(\delta + \varepsilon)$-SR and hope that its size is similar to the smallest $\delta$-SR, as there can be a gap of up to $\sqrt{d}$.

% Furthermore, our    main result has some natural directions for generalization. We considered only binary features, whereas in order to offer a practically useful tool to the community, we will need to understand how to compute (approximate) probabilistic explanations for real-valued features and categorical features. A fascinating theoretical question is whether the case of product distributions (i.e., feature $i$ takes value $1$ with probability $p_i$ and $0$ otherwise) can also be solved efficiently; for instance, a bank that judges loan applications with a linear model might give a lot of weight to the feature \emph{``has been convicted of a financial crime''}, but since the base rate of that features is probably extremely low, then it is probably not a good feature to choose in order to explain why someone who got a loan approved, since leaving that feature out of the explanation should still factor in the ``default value'' for that feature. Theoretically, the issue is that when different features have different weights and different probabilities, it is not clear what the best features to include in an explanation are. This theoretical challenge can be summarized by the following toy problem: 
% \begin{center}
% \emph{Consider $N$ lottery tickets, where ticket $i$ gives a reward $w_i$ with probability $p_i$. If all tickets cost $1$, and you have a budget of $k$, what are the best $k$ tickets to buy in order to maximize the probability of getting a total reward of at least $t$?}
% \end{center}
% Let us discuss some initial thoughts on this problem. The expected value of ticket $i$ is $p_i \cdot w_i$, but buying the top $k$ tickets according to expected value is not optimal; for a minimal example, let $(w_1 = 10, p_1 = 0.5), (w_2 = 1000, p_2 = 0.1), k = 1$; if $t  \leq 10$, then the first ticket is strictly better, but if $t > 10$ the second ticket is strictly better. The point of this example is that the order in which tickets compare to each other depends on $t$.
% Let us show a more interesting example of how the optimal tickets depend on $k$.
% Imagine that for each $i \in \{1, ..., 100\}$ we have $w_i = 100, p_i = 0.5$, and for each $i \in \{101, ..., 200\}$ we have $w_i = 15000, p_i = 0.02$. Fix $t = 1500$, and consider now that if $k = 15$, then it is better to buy only tickets from the second kind (i.e., $i \in \{101, \ldots, 200\}$). Indeed, to reach $t=1500$ with tickets from the first kind one would need all 15 of them to win, so the probability would be at most $(1/2)^{15} < 0.02$. However, if $k = 40$, then buying 40 tickets of the first kind gets $1500$ or more with high probability (Chernoff's bound), whereas for 40 tickets of the second kind the probability of reaching $t = 1500$ is $1 - (0.98)^{40} \approx 0.56$.
% In terms of related literature, this problem corresponds to a non-adaptive version of the \emph{``stochastic target''} problem~\citep{stochasticTarget}, and it ressembles a variety of stochastic problems that have been significantly studied by theoretical computer scientists~\citep{segev2023efficientapproximationschemesstochastic,ghuge2023nonadaptivestochasticscoreclassification,deanApproximatingStochasticKnapsack2008}. 
% Going back to the high level again, it seems that if we want to understand how to explain linear model under product distributions, we need to understand the lottery ticket problem. Consider for instance a bank that uses the feature \emph{``has been convicted of a financial crime''}, which when positive severely impacts the probability of the applicant getting a loan, but such a feature has a very small probability of being positive over a random applicant. Such a situation corresponds to a lottery ticket with a high reward value but low probability; depending on the specific values, it might not be a very explanatory feature, since if one does not include it in the explanation then it is almost safe to assume the applicant will not have that feature anyway. Our future work will focus on understanding this case, and more in general, on understanding the computational limits of explainability over linear models.